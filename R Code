remove(list = ls())

library(forecast)
library(ggplot2)
library(fma)
library(expsmooth)
library(fpp2)
library(seasonal)
library(mFilter) #install.packages(mFilter)

DATA = read.csv(url("https://raw.githubusercontent.com/hendrikdiers/BAN430/master/data_clean_forecasting_assigment1.csv"), header = TRUE, sep = ";", dec = "," )
DATA = na.omit(DATA) #Deleting omitted variables
GDP = ts((DATA[,2]), frequency = 4, start = c(1990, 1), end = c(2019,4))
UNEMP = ts((DATA[,3]), frequency = 4, start = c(1990, 1), end = c(2019,4))
M3 = ts(log(DATA[,4]), frequency = 4, start = c(1990, 1), end = c(2019,4)) #log transformed

cor(DATA[,2:4])


#Training Data: Q1 1990 - Q4 2014
GDP.train = window(GDP, start = 1990, end = c(2014,4))
UNEMP.train = window(UNEMP/100, start = 1990, end = c(2014,4)) #Levels
M3.train = window(M3, start = 1990, end = c(2014,4))


#Out-off sample data Q1 2015 - Q4 2019 (20)
GDP.test = window(GDP, start = (2015))
#length of forecast
h20 = 20

###Preliminary (exploratory) analysis
summary(GDP.train)
quantile(GDP.train)

#smalles observaton at the end of serie
boxplot(GDP.train,res=100, width = 1000, height = 1000) #no outliers

#outliers which need to be explained
autoplot(GDP.train)+
  ggtitle("Gross Domestic Product USA")+
  xlab("Qauter")+
  ylab("$") 


#Regression on quartaly dummies and trend
summary(tslm(log(GDP.train) ~ trend + season))


#Seasonal subseries plots to emphasises seasonal patterns
ggsubseriesplot(GDP.train)+
  ylab("Log(GDP) in $") +
  ggtitle("Seasonal subseries plot: GDP USA")

#Lag plots
gglagplot(GDP.train)+
  ylab("$ in Thousands")+ xlab("$ in Thousands")+
  ggtitle("Lagged scatterplots for GDP Norway")

#Autocorrelation plots
ggAcf(GDP.train, lag.max = 40)+
  ggtitle("Autocorrelation function for GDP Norway")
#Parctial Autocorrelation plots
ggPacf(GDP.train, lag.max = 40)+
  ggtitle("Partial Autocorrelation function for GDP Norway")

#snaive with include BoxCOx
#autoplot(snaive(GDP.train, lambda = BoxCox.lambda(GDP.train), h = h20)) + autolayer(GDP.test)
#autoplot(rwf(GDP.train, drift = TRUE, h = h20)) + autolayer(GDP.test)

###Time series decomposition

#Classical multiplicative decompostion 
#!!! Is widely used but not recommended any more
GDP.train.decomp.mult = decompose(GDP.train, type="multiplicative")
(GDP.train) %>% decompose(type="multiplicative") %>%
  autoplot() + xlab("Quater") +
  ggtitle("Classical multiplicative decomposition of GDP")

#X11 decomposition
GDP.train.decomp.x11 = (GDP.train/1000) %>% seas(x11="")
autoplot(GDP.train.decomp.x11) +
  xlab("Quater") +
  ggtitle("X11 decomposition of GDP")

#SEATS decomposition
#Seasonal Extraction in ARIMA Time Series
GDP.train %>% seas() %>%
  autoplot() +
  ggtitle("SEATS decompostion of GDP")

#STL decomposition (Chapter 6.6)
#Seasonal and Trend decompostion using Loess
#several advantages over the other decomposing methods
GDP.train.decomp.stl = stl(GDP.train, t.window = 13, s.window = "periodic"  , robust = TRUE)
autoplot(GDP.train.decomp.stl) +
  ggtitle("STL decompostion of GDP")

#Seasonal adjustment: Plotting STL trend component with unadjusted GDP
autoplot(GDP.train, series = "GDP") +
  autolayer(GDP.train.decomp.stl$time.series[,2], series = "GDP seas. adj.")+
  xlab("Quater")+ylab("GDP in Thousands")+
  ggtitle("GDP and STL trend component")

#Decomposing GDP over total time horizant and extracting test period
GDP.decomp.stl = stl(GDP, t.window = 13, s.window = "periodic"  , robust = TRUE)
GDP.decomp.stl.test.sea = window(GDP.decomp.stl$time.series[,1], start = c(2015), end = c(2019,4))
GDP.decomp.stl.test.trend = window(GDP.decomp.stl$time.series[,2], start = c(2015), end = c(2019,4))
GDP.decomp.stl.test.remain = window(GDP.decomp.stl$time.series[,3], start = c(2015), end = c(2019,4))

#Business cycle
#auf seasonal adjusted
GDP.filter.seasadj = hpfilter(GDP.decomp.stl$time.series[,2], drift=TRUE)
GDP.filter.seasadj.cycle = ts(GDP.filter.seasadj$cycle, start = c(1990, 1), end = c(2019, 4), frequency = 4)

#auf Rohdaten
GDP.filter.roh = hpfilter(GDP, drift=TRUE)
GDP.filter.roh.cycle = ts(GDP.filter.roh$cycle, start = c(1990, 1), end = c(2019, 4), frequency = 4)

ggplot()+
  autolayer(GDP.filter.seasadj.cycle, series = "Seasonal adjusted")+
  autolayer(GDP.filter.roh.cycle, series = "Seasonal unadjusted")+xlab("Quater")+ylab("Business Cycle")

###Forecasting the componantes of the series

#Used decomposition method: STL
GDP.train.decomp.stl.sea = GDP.train.decomp.stl$time.series[,1]
GDP.train.decomp.stl.trend = GDP.train.decomp.stl$time.series[,2]
GDP.train.decomp.stl.remai = GDP.train.decomp.stl$time.series[,3]

#Forecasting the tend

###Trend Forecast 
GDP.train.decomp.stl.trend.fore = forecast(GDP.train.decomp.stl.trend, h = h20)
ggplot() +
  autolayer(GDP.train.decomp.stl.trend.fore, series = "Trend Forecast")+
  autolayer(GDP.decomp.stl.test.trend, series = "Trend in Test Data")+
  ggtitle("Forecast of trend from decomposed series") + ylab("Quater")

#Froecasting the Seasonality
GDP.train.decomp.stl.sea.fore = forecast(GDP.train.decomp.stl.sea, h = h20)
ggplot() +
  autolayer(GDP.train.decomp.stl.sea.fore, series = "Seasonal Forecast")+
  autolayer(GDP.decomp.stl.test.sea, series = "Seasonality in Test Data")+
  ggtitle("Forecast of Seasonality from decomposed series")

#Froecasting the Remaining
GDP.train.decomp.stl.remai.fore = forecast(GDP.train.decomp.stl.remai, h = h20)
ggplot() +
  autolayer(GDP.train.decomp.stl.remai.fore, series = "Remaining Forecast")+
  autolayer(GDP.decomp.stl.test.remain, series = "Remaining in Test Data")+
  ggtitle("Forecast of Remaining from decomposed series")

#Forecast unsing the forecast of the three componants
GDP.train.decomp.stl.add.mean = (GDP.train.decomp.stl.remai.fore$mean +
                                   GDP.train.decomp.stl.sea.fore$mean +
                                   GDP.train.decomp.stl.trend.fore$mean)
GDP.train.decomp.stl.add.upper = (GDP.train.decomp.stl.remai.fore$upper +
                                    GDP.train.decomp.stl.sea.fore$upper +
                                    GDP.train.decomp.stl.trend.fore$upper)
GDP.train.decomp.stl.add.lower = (GDP.train.decomp.stl.remai.fore$lower +
                                    GDP.train.decomp.stl.sea.fore$lower +
                                    GDP.train.decomp.stl.trend.fore$lower)
ggplot()+
  autolayer(window(GDP.train, start = c(2005,1)), series = "Taining Data")+
  autolayer(GDP.train.decomp.stl.add.upper[,1], series = "Upper Forecast")+
  autolayer(GDP.train.decomp.stl.add.mean, series = "Mean Forecast")+
  autolayer(GDP.train.decomp.stl.add.lower[,1], series = "Lower Forecast")+            
  autolayer(GDP.test, series = "Test Data")+
  ggtitle("Forecast by additiv decomponant forecast")

#Selecting an appropriate ETS model
GDP.train.ets.auto = ets(GDP.train, model="ZZZ", damped=FALSE, additive.only = FALSE)
summary(GDP.train.ets.auto)
autoplot(GDP.train.ets.auto)
GDP.train.ets.auto.fore = forecast(GDP.train.ets.auto, h = 20)

ggplot()+
  autolayer(window(GDP.train, start = c(2005,1)), series = "Training Data")+
  autolayer(GDP.train.ets.auto.fore, series = "Forecast from EST(M,A,M)")+
  autolayer(GDP.test, series = "Test Data")+
  ggtitle("Forecasting with ETS(M,A,M) model")+ ylab("Log(GDP) in $")+xlab("Quater")


#Simple forecasting methods to compare with
autoplot(window(GDP.train, start = c(2005,1))) +
  autolayer(meanf(GDP.train, h = h20, bootstrap = TRUE), series = "Mean", PI = FALSE)+
  autolayer(naive(GDP.train, h = h20, bootstrap = TRUE), series = "Naive", PI = FALSE)+
  autolayer(snaive(GDP.train, h =  h20, bootstrap = TRUE, drift = TRUE), series = "Sesonal naive", PI = FALSE)+
  autolayer(rwf(GDP.train, h = h20, drift = TRUE, bootstrap = TRUE), series = "Random Walk with drift", PI = FALSE)+
  autolayer(rwf(GDP.train, h = h20, drift = FALSE, bootstrap = TRUE), series = "Random Walk", PI = FALSE)+
  autolayer(GDP.test, series = "DATA")+
  ggtitle("Forcast for quarterly GDP")+
  xlab("Quater")+ylab("$ in Thousands")+
  guides(colour=guide_legend(title="Forecast"))
#visualy the random walk with drift forecast seems to be the best out of the basic forecast methods
#random walk forecast with drif will be used to compare with other forecast methods

###Exponential Smoothing
#Holt's Method      
GDP.train.fore.holt = holt(GDP.train, h = h20, dumped = FALSE)
#Damped Holt's Method: Decreasing trend
#damped Holt's method seems to be unappropriated
#Holt-Winters additive method: Seasonality
GDP.train.fore.hw1 = hw(GDP.train, seasonal = "additiv", h = h20) 
GDP.train.fore.hw2 = hw(GDP.train, seasonal = "multiplicativ", h = h20)

autoplot(window(GDP.train, start = c(2005,1)))+
  autolayer(GDP.test, series = "Test Data")+
  autolayer(GDP.train.fore.holt, series = "Holt's method", PI = FALSE)+
  autolayer(GDP.train.fore.hw1, series = "HW additiv forecast", PI = FALSE)+
  autolayer(GDP.train.fore.hw2, series = "HW multipicativ forecast", PI = FALSE)+
  ggtitle("Forecast GDP from Holt's method")+
  xlab("Quaters")+ylab("$")+guides(colours=guide_legend(title = "Forecast"))
#Visualy the additiv Holt-Winter forecast seems to be the best out of the exponential soomthing forecast methods
#Holt-Winters additive method will be used to compare with other forecast methods

#Plot the most three advanced forecasts
ggplot()+
  autolayer(window(GDP.train, start = c(2005,1)), series = "Training Data")+
  autolayer(forecast(GDP.train.ets.auto, h = 20),PI = FALSE, series = "Forecast with estimated EST(M,A,A")+
  autolayer(GDP.train.fore.hw1, series = "HW additiv forecast",PI = FALSE)+
  autolayer(rwf(GDP.train, h = h20, drift = TRUE, bootstrap = TRUE), series = "Random Walk with drift", PI = FALSE)+
  autolayer(GDP.test, series = "Test Data") + ggtitle("Diffrent Forecast methods compared") + xlab("Quater")+
  ylab("log(GDP) in $")

#Compare distribution of residuals from choosen series
checkresiduals(rwf(GDP.train, drift = TRUE, h = h20))
checkresiduals(GDP.train.fore.hw1)
checkresiduals(GDP.train.ets.auto)



#Evaluating forecast accuracy
##Scale dependent errors
#MAE: Mean absolute error
#RMSE: Root mean sqared error
##Percentage errors
#MAPE: Mean absolute precentage error
##Scaled errors
#MASE: mean absolute scaled error; nicht empfohglen fÃ¼r seasonal ts

GDP.train.accu.rwf = accuracy(rwf(GDP.train, drift = TRUE, h = h20), GDP.test)
GDP.train.accu.hw1 = accuracy(hw(GDP.train, seasonal = "additiv", h = h20), GDP.test)
GDP.train.accu.ets = accuracy(f = forecast(GDP.train.ets.auto, h = h20), GDP.test)
GDP.train.accu = as.data.frame(matrix(cbind(GDP.train.accu.rwf[2,], GDP.train.accu.hw1[2,], GDP.train.accu.ets[2,]), 3, 8)
                               , row.names = c("RANDOM W.", "HW additiv forecast", "EST(M,A,A)"))
colnames(GDP.train.accu) = colnames(GDP.train.accu.rwf)
round(GDP.train.accu, digits = 4)

###Forecasts using splines and Box-Cox
#Box-Cox
lambda = BoxCox.lambda(GDP.train)
#Lambda = 0.1949816
GDP.train.box = BoxCox(GDP.train, lambda)
autoplot(GDP.train.box)+
  ggtitle("GDP Box-Cox transformed")+xlab("Quater")+ylab("GDP")

#With and without bias adjustment
GDP.train.box.fore.non = rwf(GDP.train.box, drift=TRUE, lambda=lambda, h=h20, level=80)
GDP.train.box.fore.adj = rwf(GDP.train.box, drift=TRUE, lambda=lambda, h=h20, level=80, biasadj=TRUE)

autoplot(window(GDP.train.box, start = c(2005,1)), series = "Training Data") +
  autolayer(GDP.train.box.fore.adj, series="Bias adjusted") +
  autolayer(GDP.train.box.fore.non, series="Simple back transformation", PI=FALSE) +
  autolayer(BoxCox(GDP.test, lambda), series = "Test Data")+ ylab("GDP")+xlab("Quater")+ggtitle("Forecasting GDP with Box-Cox transformation")+
  guides(colour=guide_legend(title="Forecast"))
#As it could visualy be recognized: Adjusting the bias has not much of an influence
checkresiduals(GDP.train.box.fore.adj)

#Splines
GDP.train.spline = splinef(GDP.train, lambda = 0, h = 20) #lambda = 0, Log() transformation
autoplot(window(GDP.train, start = c(2005,1)), series = "Training Data")+
  autolayer(GDP.train.spline, series = "Forecast")+
  autolayer(GDP.test, series = "Test Data")+
  ggtitle("Forecasting GDP with Natural cubic smoothing splines") + ylab("GDP") + xlab("Quater")
checkresiduals(GDP.train.spline)

#Compare both forecasts
autoplot(window(GDP.train, start = c(2005,1)), series = "Training Data")+
  autolayer(GDP.train.box.fore.adj, series="Bias adjusted", PI = FALSE) +
  autolayer(GDP.train.spline, series = "Forecast from Splines", PI = FALSE)+
  autolayer(GDP.test, series = "Test Data")+
  ylab("GDP") + xlab("Quater") + ggtitle("Comparing Forecast methods: Box-Cox and Natural cubic smoothing splines") 
  
  



###Integrating other variables
GDP.train.diff = diff(log(GDP.train), lag = 1)
UNEMP.train.level = window(UNEMP.train, start = c(1990,2))
M3.train.diff = diff(M3.train, lag = 1)

autoplot(GDP.train.diff)+
  autolayer(M3.train.diff)+
  autolayer(UNEMP.train.level)

autoplot(cbind(GDP.train.diff, UNEMP.train.level, M3.train.diff), facets = TRUE)+
  ggtitle("First Difference Log(GDP") + xlab("Quater") + ylab("")

qplot(GDP.train.diff, M3.train.diff, asp = 1) +
  ylab("First Difference log(M3)") + xlab("First Difference log(GDP)")+
  ggtitle("Scatterplot: First differences log(GDP) - log(M3)")

qplot(GDP.train.diff, UNEMP.train.level, asp = 1) +
  ylab("Unemployment Rate") + xlab("First Difference log(GDP)")+
  ggtitle("Scatterplot: First difference log(GDP) - Unemploymant Rate")


GDP.train.fit = tslm(GDP.train.diff ~ M3.train.diff + UNEMP.train.level + season) #as obvious, there should not be a trend
summary(GDP.train.fit)
round(CV(GDP.train.fit), digits = 4)

GDP.train.fit.fore1 = forecast(GDP.train.fit,
                              newdata = data.frame(
                                M3.train.diff = rep(mean(M3.train.diff), h20),
                                UNEMP.train.level = rep(mean(UNEMP.train.level),h20)),
                              h = h20)

GDP.train.fit.fore2 = forecast(GDP.train.fit,
                              newdata = data.frame(
                                M3.train.diff = rep(mean(M3.train.diff), h20),
                                UNEMP.train.level = rep(5*mean(UNEMP.train.level),h20)),
                              h = h20)

autoplot(window(GDP.train.diff, start = c(2005,1)), series = "Training Data")+
  autolayer(GDP.train.fit.fore1, series = "Mean Unemployment")+
  autolayer(GDP.train.fit.fore2, series = "Five times the Mean Unemployment rate")+
  autolayer(diff(log(GDP.test), lag = 1), series = "Test Data")+
  ggtitle("Forecasting first differenc Log(GDP) with diffrent Unemployment rates")+xlab("Quater")+ylab("Differnce")


#Portmanteau tests for autocorrelation
#Test if errors are coming from a white noise series
#Box Pierce test
Box.test(GDP.train.ets$residuals, lag = 10, fitdf = 0)
#Box-Ljung test
Box.test(GDP.train.ets$residuals, lag = 10, fitdf = 0, type = "Lj")
#We can conclude that the residuals can be distingushed from a white noise series



##Scatterplots to explore relationships between timeseries
autoplot(cbind(GDP.train.diff, UNEMP.train.level, M3.train.diff), facets = TRUE)+
  ggtitle("First Difference Log(GDP") + xlab("Quater") + ylab("")

qplot(GDP.train.diff, M3.train.diff, asp = 1) +
  ylab("First Difference log(M3)") + xlab("First Difference log(GDP)")+
  ggtitle("Scatterplot: First differences log(GDP) - log(M3)")

qplot(GDP.train.diff, UNEMP.train.level, asp = 1) +
  ylab("Unemployment Rate") + xlab("First Difference log(GDP)")+
  ggtitle("Scatterplot: First difference log(GDP) - Unemploymant Rate")


#time series cross-validation !!!Diese Funktion gilt es nachzubilden
#Kapitel 3.4 
GDPfore = tsCV(GDP.train, rwf, drift = TRUE, h = 8) 
summary(GDPfore)


GDPforeMSE = colMeans(GDPfore, na.rm = TRUE)
data.frame(h = 1:8, MSE = GDPforeMSE) %>%
  ggplot(aes(x = h, y = GDPforeMSE)) + geom_point()

sqrt(mean(GDPfore^2, na.rm = TRUE))


qplot()
?autoplot()


##'!!!! Information Creteria: AIC!!!! Prefered
